{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from custom_cmap import custom_cmap\n",
    "from copy import deepcopy as copy\n",
    "import einops\n",
    "import fit_trunc_dist\n",
    "from functools import partial\n",
    "import glob\n",
    "from icecream import ic\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from numpy import sqrt, pi, exp\n",
    "from numba import jit, prange\n",
    "from parse_swag_args import parse\n",
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.special import erf\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import quad\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import spock_reg_model\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import utils\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ARGS, CHECKPOINT_FILENAME = parse(glob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1761033/2348279177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m swag_ensemble = [\n\u001b[1;32m      4\u001b[0m     \u001b[0mspock_reg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_swag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1761033/2348279177.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m swag_ensemble = [\n\u001b[1;32m      4\u001b[0m     \u001b[0mspock_reg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_swag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/pytorch_lightning/utilities/device_dtype_mixin.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "\n",
    "global ARGS, CHECKPOINT_FILENAME\n",
    "s = CHECKPOINT_FILENAME + \"*output.pkl\"\n",
    "swag_ensemble = [\n",
    "    spock_reg_model.load_swag(fname).cuda()\n",
    "    for fname in glob.glob(s) #\n",
    "]\n",
    "\n",
    "if len(swag_ensemble) == 0:\n",
    "    raise ValueError(s + \" not found!\")\n",
    "\n",
    "\n",
    "if ARGS.plot_random:\n",
    "    CHECKPOINT_FILENAME += '_random'\n",
    "\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colorstr = \"\"\"*** Primary color:\n",
    "\n",
    "   shade 0 = #A0457E = rgb(160, 69,126) = rgba(160, 69,126,1) = rgb0(0.627,0.271,0.494)\n",
    "   shade 1 = #CD9CBB = rgb(205,156,187) = rgba(205,156,187,1) = rgb0(0.804,0.612,0.733)\n",
    "   shade 2 = #BC74A1 = rgb(188,116,161) = rgba(188,116,161,1) = rgb0(0.737,0.455,0.631)\n",
    "   shade 3 = #892665 = rgb(137, 38,101) = rgba(137, 38,101,1) = rgb0(0.537,0.149,0.396)\n",
    "   shade 4 = #74104F = rgb(116, 16, 79) = rgba(116, 16, 79,1) = rgb0(0.455,0.063,0.31)\n",
    "\n",
    "*** Secondary color (1):\n",
    "\n",
    "   shade 0 = #CDA459 = rgb(205,164, 89) = rgba(205,164, 89,1) = rgb0(0.804,0.643,0.349)\n",
    "   shade 1 = #FFE9C2 = rgb(255,233,194) = rgba(255,233,194,1) = rgb0(1,0.914,0.761)\n",
    "   shade 2 = #F1D195 = rgb(241,209,149) = rgba(241,209,149,1) = rgb0(0.945,0.82,0.584)\n",
    "   shade 3 = #B08431 = rgb(176,132, 49) = rgba(176,132, 49,1) = rgb0(0.69,0.518,0.192)\n",
    "   shade 4 = #956814 = rgb(149,104, 20) = rgba(149,104, 20,1) = rgb0(0.584,0.408,0.078)\n",
    "\n",
    "*** Secondary color (2):\n",
    "\n",
    "   shade 0 = #425B89 = rgb( 66, 91,137) = rgba( 66, 91,137,1) = rgb0(0.259,0.357,0.537)\n",
    "   shade 1 = #8C9AB3 = rgb(140,154,179) = rgba(140,154,179,1) = rgb0(0.549,0.604,0.702)\n",
    "   shade 2 = #697DA0 = rgb(105,125,160) = rgba(105,125,160,1) = rgb0(0.412,0.49,0.627)\n",
    "   shade 3 = #294475 = rgb( 41, 68,117) = rgba( 41, 68,117,1) = rgb0(0.161,0.267,0.459)\n",
    "   shade 4 = #163163 = rgb( 22, 49, 99) = rgba( 22, 49, 99,1) = rgb0(0.086,0.192,0.388)\n",
    "\n",
    "*** Complement color:\n",
    "\n",
    "   shade 0 = #A0C153 = rgb(160,193, 83) = rgba(160,193, 83,1) = rgb0(0.627,0.757,0.325)\n",
    "   shade 1 = #E0F2B7 = rgb(224,242,183) = rgba(224,242,183,1) = rgb0(0.878,0.949,0.718)\n",
    "   shade 2 = #C9E38C = rgb(201,227,140) = rgba(201,227,140,1) = rgb0(0.788,0.89,0.549)\n",
    "   shade 3 = #82A62E = rgb(130,166, 46) = rgba(130,166, 46,1) = rgb0(0.51,0.651,0.18)\n",
    "   shade 4 = #688C13 = rgb(104,140, 19) = rgba(104,140, 19,1) = rgb0(0.408,0.549,0.075)\"\"\"\n",
    "\n",
    "colors = []\n",
    "shade = 0\n",
    "for l in colorstr.replace(' ', '').split('\\n'):\n",
    "    elem = l.split('=')\n",
    "    if len(elem) != 5: continue\n",
    "    if shade == 0:\n",
    "        new_color = []\n",
    "    rgb = lambda x, y, z: np.array([x, y, z]).astype(np.float32)\n",
    "\n",
    "    new_color.append(eval(elem[2]))\n",
    "\n",
    "    shade += 1\n",
    "    if shade == 5:\n",
    "        colors.append(np.array(new_color))\n",
    "        shade = 0\n",
    "colors = np.array(colors)/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "swag_ensemble[0].make_dataloaders()\n",
    "if ARGS.plot_random:\n",
    "    assert swag_ensemble[0].ssX is not None\n",
    "    tmp_ssX = copy(swag_ensemble[0].ssX)\n",
    "    # print(tmp_ssX.mean_)\n",
    "    if ARGS.train_all:\n",
    "        swag_ensemble[0].make_dataloaders(\n",
    "            ssX=swag_ensemble[0].ssX,\n",
    "            train=True,\n",
    "            plot_random=True)\n",
    "    else:\n",
    "        swag_ensemble[0].make_dataloaders(\n",
    "            ssX=swag_ensemble[0].ssX,\n",
    "            train=False,\n",
    "            plot_random=True) #train=False means we show the whole dataset (assuming we don't train on it!)\n",
    "\n",
    "    # print(swag_ensemble[0].ssX.mean_)\n",
    "    assert np.all(tmp_ssX.mean_ == swag_ensemble[0].ssX.mean_)\n",
    "\n",
    "val_dataloader = swag_ensemble[0]._val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_full_swag(X_sample):\n",
    "    \"\"\"Pick a random model from the ensemble and sample from it\n",
    "    within each model, it samples from its weights.\"\"\"\n",
    "\n",
    "    swag_i = np.random.randint(0, len(swag_ensemble))\n",
    "    swag_model = swag_ensemble[swag_i]\n",
    "    swag_model.eval()\n",
    "    swag_model.w_avg = swag_model.w_avg.cuda()\n",
    "    swag_model.w2_avg = swag_model.w2_avg.cuda()\n",
    "    swag_model.pre_D = swag_model.pre_D.cuda()\n",
    "    swag_model.cuda()\n",
    "    out = swag_model.forward_swag(X_sample, scale=0.5)\n",
    "    return out\n",
    "\n",
    "truths = []\n",
    "preds = []\n",
    "raw_preds = []\n",
    "\n",
    "nc = 0\n",
    "losses = 0.0\n",
    "do_sample = True\n",
    "for X_sample, y_sample in tqdm(val_dataloader):\n",
    "    X_sample = X_sample.cuda()\n",
    "    y_sample = y_sample.cuda()\n",
    "    nc += len(y_sample)\n",
    "    truths.append(y_sample.cpu().detach().numpy())\n",
    "\n",
    "    raw_preds.append(\n",
    "        np.array([sample_full_swag(X_sample).cpu().detach().numpy() for _ in range(2000)])\n",
    "    )\n",
    "\n",
    "truths = np.concatenate(truths)\n",
    "\n",
    "_preds = np.concatenate(raw_preds, axis=1)\n",
    "\n",
    "# numpy sampling is way too slow:\n",
    "\n",
    "\n",
    "def fast_truncnorm(\n",
    "        loc, scale, left=np.inf, right=np.inf,\n",
    "        d=10000, nsamp=50, seed=0):\n",
    "    \"\"\"Fast truncnorm sampling.\n",
    "\n",
    "    Assumes scale and loc have the desired shape of output.\n",
    "    length is number of elements.\n",
    "    Select nsamp based on expecting at last one sample\n",
    "        to fit within your (left, right) range.\n",
    "    Select d based on memory considerations - need to operate on\n",
    "        a (d, nsamp) array.\n",
    "    \"\"\"\n",
    "    oldscale = scale\n",
    "    oldloc = loc\n",
    "\n",
    "    scale = scale.reshape(-1)\n",
    "    loc = loc.reshape(-1)\n",
    "    samples = np.zeros_like(scale)\n",
    "    start = 0\n",
    "\n",
    "    for start in range(0, scale.shape[0], d):\n",
    "\n",
    "        end = start + d\n",
    "        if end > scale.shape[0]:\n",
    "            end = scale.shape[0]\n",
    "\n",
    "        cd = end-start\n",
    "        rand_out = np.random.randn(\n",
    "            nsamp, cd\n",
    "        )\n",
    "\n",
    "        rand_out = (\n",
    "            rand_out * scale[None, start:end]\n",
    "            + loc[None, start:end]\n",
    "        )\n",
    "\n",
    "        #rand_out is (nsamp, cd)\n",
    "        if right == np.inf:\n",
    "            mask = (rand_out > left)\n",
    "        elif left == np.inf:\n",
    "            mask = (rand_out < right)\n",
    "        else:\n",
    "            mask = (rand_out > left) & (rand_out < right)\n",
    "\n",
    "        first_good_val = rand_out[\n",
    "            mask.argmax(0), np.arange(cd)\n",
    "        ]\n",
    "\n",
    "        samples[start:end] = first_good_val\n",
    "\n",
    "    return samples.reshape(*oldscale.shape)\n",
    "\n",
    "std = _preds[..., 1]\n",
    "mean = _preds[..., 0]\n",
    "\n",
    "loc = mean\n",
    "scale = std\n",
    "\n",
    "sample_preds = np.array(\n",
    "        fast_truncnorm(np.array(mean), np.array(std),\n",
    "               left=4, d=874000, nsamp=40));\n",
    "\n",
    "stable_past_9 = sample_preds >= 9\n",
    "\n",
    "\n",
    "_prior = lambda logT: (\n",
    "    3.27086190404742*np.exp(-0.424033970670719 * logT) -\n",
    "    10.8793430454878*np.exp(-0.200351029031774 * logT**2)\n",
    ")\n",
    "normalization = quad(_prior, a=9, b=np.inf)[0]\n",
    "\n",
    "prior = lambda logT: _prior(logT)/normalization\n",
    "\n",
    "# Let's generate random samples of that prior:\n",
    "\n",
    "\n",
    "n_samples = stable_past_9.sum()\n",
    "bins = n_samples*4\n",
    "top = 100.\n",
    "bin_edges = np.linspace(9, top, num=bins)\n",
    "cum_values = [0] + list(np.cumsum(prior(bin_edges)*(bin_edges[1] - bin_edges[0]))) + [1]\n",
    "bin_edges = [9.] +list(bin_edges)+[top]\n",
    "inv_cdf = interp1d(cum_values, bin_edges)\n",
    "r = np.random.rand(n_samples)\n",
    "samples = inv_cdf(r)\n",
    "\n",
    "sample_preds[stable_past_9] = samples\n",
    "\n",
    "_preds.shape\n",
    "\n",
    "# # expectation of samples\n",
    "# preds = np.average(sample_preds, 0)\n",
    "# stds = np.std(sample_preds, 0)\n",
    "\n",
    "# # median of samples\n",
    "# preds = np.median(sample_preds, 0)\n",
    "# stds = (\n",
    "#     (lambda x: 0.5*(np.percentile(x, q=50 + 68/2, axis=0) - np.percentile(x, q=50-68/2, axis=0)))\n",
    "#     (sample_preds)\n",
    "# )\n",
    "\n",
    "# # median of dists\n",
    "preds = np.median(_preds[..., 0], 0)\n",
    "stds = np.median(_preds[..., 1], 0)\n",
    "\n",
    "# # fit a truncated dist using avg, var\n",
    "# tmp = fit_trunc_dist.find_mu_sig(sample_preds.T)\n",
    "# preds = tmp[:, 0]\n",
    "# stds = tmp[:, 1]\n",
    "\n",
    "# # with likelihood (slow)\n",
    "# tmp = fit_trunc_dist.find_mu_sig_likelihood(sample_preds[:300, :].T)\n",
    "# preds = tmp[:, 0]\n",
    "# stds = tmp[:, 1]\n",
    "\n",
    "# weighted average of mu\n",
    "# w_i = 1/_preds[:, :, 1]**2\n",
    "# w_i /= np.sum(w_i, 0)\n",
    "# preds = np.average(_preds[:, :, 0], 0, weights=w_i)\n",
    "# stds = np.average(_preds[:, :, 1]**2, 0)**0.5\n",
    "\n",
    "# Check that confidence intervals are satisifed. Calculate mean and std of samples. Take abs(truths - mean)/std = sigma. The CDF of this distrubtion should match that of a Gaussian. Otherwise, rescale \"scale\".\n",
    "\n",
    "tmp_mask = (truths > 6) & (truths < 7) #Take this portion since its far away from truncated parts\n",
    "averages = preds#np.average(sample_preds, 0)\n",
    "gaussian_stds = stds#np.std(sample_preds, 0)\n",
    "sigma = (truths[tmp_mask] - np.tile(averages, (2, 1)).T[tmp_mask])/np.tile(gaussian_stds, (2, 1)).T[tmp_mask]\n",
    "\n",
    "np.save(CHECKPOINT_FILENAME + 'model_error_distribution.npy', sigma)\n",
    "\n",
    "bins = 30\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.hist(np.abs(sigma), bins=bins, range=[0, 2.5], density=True,\n",
    "            color=colors[0, 3],\n",
    "         alpha=1, label='Model error distribution')\n",
    "np.random.seed(0)\n",
    "plt.hist(np.abs(np.random.randn(len(sigma))), bins=bins, range=[0, 2.5], density=True,\n",
    "            color=colors[1, 3],\n",
    "         alpha=0.5, label='Gaussian distribution')\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.xlabel('Error over sigma', fontsize=14)\n",
    "# plt.xlabel('$|\\mu_θ - y|/\\sigma_θ$', fontsize=14)\n",
    "plt.legend()\n",
    "fig.savefig(CHECKPOINT_FILENAME + 'error_dist.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Looks great! We didn't even need to tune it. Just use the same scale as the paper (0.5). Perhaps, however, with epistemic uncertainty, we will need to tune.\n",
    "\n",
    "\n",
    "def density_scatter(x, y, xlabel='', ylabel='', clabel='Sample Density', log=False,\n",
    "    width_mult=1, bins=30, p_cut=None, update_rc=True, ax=None, fig=None, cmap='viridis', **kwARGS):\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    xy = np.array([x, y]).T\n",
    "    px = xy[:, 0]\n",
    "    py = xy[:, 1]\n",
    "    if p_cut is not None:\n",
    "        p = p_cut\n",
    "        range_x = [np.percentile(xy[:, 0], i) for i in [p, 100-p]]\n",
    "        range_y = [np.percentile(xy[:, 1], i) for i in [p, 100-p]]\n",
    "        pxy = xy[(xy[:, 0] > range_x[0]) & (xy[:, 0] < range_x[1]) & (xy[:, 1] > range_y[0]) & (xy[:, 1] < range_y[1])]\n",
    "    else:\n",
    "        pxy = xy\n",
    "    px = pxy[:, 0]\n",
    "    py = pxy[:, 1]\n",
    "    norm = None\n",
    "    if log:\n",
    "        norm = LogNorm()\n",
    "\n",
    "    h, xedge, yedge, im = ax.hist2d(\n",
    "        px, py, density=True, norm=norm,\n",
    "        bins=[int(width_mult*bins), bins], cmap=cmap, **kwARGS)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    fig.colorbar(im, ax=ax).set_label(clabel)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "_preds.shape\n",
    "\n",
    "#confidences_to_plot = 'low med high vhigh vvhigh'.split(' ')\n",
    "confidences_to_plot = ['low']\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "show_transparency = True\n",
    "\n",
    "main_shade = 3\n",
    "main_color = colors[2, main_shade]\n",
    "off_color = colors[2, main_shade]\n",
    "\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_style('white')\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "# +\n",
    "for confidence in confidences_to_plot:\n",
    "    py = preds\n",
    "    py = np.clip(py, 4, 9)\n",
    "    px = np.average(truths, 1)\n",
    "\n",
    "    mask = np.all(truths < 9.99, 1) # np.all(truths < 8.99, 1)\n",
    "\n",
    "    if confidence != 'low':\n",
    "        #tmp_std = np.std(sample_preds, 0)/py\n",
    "        tmp_std = stds/py\n",
    "        if confidence == 'high':\n",
    "            mask = mask & ((tmp_std) < np.percentile(tmp_std[mask], 50))\n",
    "        elif confidence == 'vhigh':\n",
    "            mask = mask & ((tmp_std) < np.percentile(tmp_std[mask], 25))\n",
    "        elif confidence == 'vvhigh':\n",
    "            mask = mask & ((tmp_std) < np.percentile(tmp_std[mask], 10))\n",
    "        elif confidence == 'med':\n",
    "            mask = mask & ((tmp_std) < np.percentile(tmp_std[mask], 70))\n",
    "\n",
    "    ppx = px[mask]\n",
    "    ppy = py[mask]\n",
    "    p_std = stds[mask]\n",
    "\n",
    "\n",
    "    extra = ''\n",
    "    if confidence != 'low':\n",
    "        extra = ', '\n",
    "        extra += {\n",
    "            'med': '30th',\n",
    "            'high': '50th',\n",
    "            'vhigh': '75th',\n",
    "            'vvhigh': '90th',\n",
    "        }[confidence]\n",
    "        extra += ' percentile confidence'\n",
    "    title = 'Our model'+extra\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4),\n",
    "                     dpi=300,\n",
    "                     constrained_layout=True)\n",
    "    # if ARGS.plot_random:\n",
    "        # ic('random')\n",
    "        # ic(len(ppx))\n",
    "        # alpha = min([0.05 * 72471 / len(ppx), 1.0])\n",
    "    # else:\n",
    "        # ic('not random')\n",
    "        # ic(len(ppx))\n",
    "\n",
    "#     alpha = min([0.05 * 8740 / len(ppx), 1.0])\n",
    "#     ic(alpha, ARGS.plot_random, len(ppx))\n",
    "    alpha = 1.0\n",
    "\n",
    "    #colors[2, 3]\n",
    "    main_color = main_color.tolist()\n",
    "    g = sns.jointplot(ppx, ppy,\n",
    "                    alpha=alpha,# ax=ax,\n",
    "                      color=main_color,\n",
    "#                     hue=(ppy/p_std)**2,\n",
    "                    s=0.0,\n",
    "                    xlim=(3, 10),\n",
    "                    ylim=(3, 10),\n",
    "                    marginal_kws=dict(bins=15),\n",
    "                   )\n",
    "\n",
    "    ax = g.ax_joint\n",
    "    snr = (ppy/p_std)**2\n",
    "    relative_snr = snr / max(snr)\n",
    "    point_color = relative_snr\n",
    "\n",
    "    rmse = np.average(np.square(ppx[ppx < 8.99] - ppy[ppx < 8.99]))**0.5\n",
    "    snr_rmse = np.average(np.square(ppx[ppx < 8.99] - ppy[ppx < 8.99]), weights=snr[ppx<8.99])**0.5\n",
    "    print(f'{confidence} confidence gets RMSE of {rmse:.2f}')\n",
    "    print(f'Weighted by SNR, this is: {snr_rmse:.2f}')\n",
    "    # np.save(ppx, f'ppx_{ARGS.version}.npy')\n",
    "    # np.save(ppx, f'ppy_{ARGS.version}.npy')\n",
    "\n",
    "    ######################################################\n",
    "    # Bias scores:\n",
    "    tmpdf = pd.DataFrame({'true': ppx, 'pred': ppy, 'w': snr})\n",
    "    for lo in range(4, 9):\n",
    "        hi = lo + 0.99\n",
    "        considered = tmpdf.query(f'true>{lo} & true<{hi}')\n",
    "        print(f\"Between {lo} and {hi}, the bias is {np.average(considered['pred'] - considered['true']):.3f}\",\n",
    "                f\"and the weighted bias is {np.average(considered['pred'] - considered['true'], weights=considered['w']):.3f}\")\n",
    "    ######################################################\n",
    "\n",
    "    #Transparency:\n",
    "    if show_transparency:\n",
    "        if ARGS.plot_random:\n",
    "            transparency_adjuster = 1.0 #0.5 * 0.2\n",
    "        else:\n",
    "            transparency_adjuster = 1.0\n",
    "        point_color = np.concatenate(\n",
    "            (einops.repeat(colors[2, 3], 'c -> row c', row=len(ppy)),\n",
    "             point_color[:, None]*transparency_adjuster), axis=1)\n",
    "    #color mode:\n",
    "    else:\n",
    "        point_color = np.einsum('r,i->ir', main_color, point_color) +\\\n",
    "            np.einsum('r,i->ir', off_color, 1-point_color)\n",
    "\n",
    "\n",
    "\n",
    "    im = ax.scatter(\n",
    "                ppx,\n",
    "               ppy, marker='o',\n",
    "               c=point_color,\n",
    "               s=10,\n",
    "               edgecolors='none'\n",
    "              )\n",
    "    ax.plot([4-3, 9+3], [4-3, 9+3], color='k')\n",
    "    ax.plot([4-3, 9+3], [4+0.61-3, 9+0.61+3], color='k', ls='--')\n",
    "    ax.plot([4-3, 9+3], [4-0.61-3, 9-0.61+3], color='k', ls='--')\n",
    "    ax.set_xlim(3+0.9, 10-0.9)\n",
    "    ax.set_ylim(3+0.9, 10-0.9)\n",
    "    ax.set_xlabel('Truth')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.suptitle(title, y=1.0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if confidence == 'low':\n",
    "        plt.savefig(CHECKPOINT_FILENAME + 'comparison.png', dpi=300)\n",
    "    else:\n",
    "        plt.savefig(CHECKPOINT_FILENAME + f'_{confidence}_confidence_' + 'comparison.png', dpi=300)\n",
    "\n",
    "    if logger:\n",
    "        logger.log_metrics({\"comparison\": wandb.Image(plt)})\n",
    "\n",
    "# +\n",
    "\n",
    "mymap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "    'mine', [\n",
    "        [1.0, 1.0, 1.0, 1.0],\n",
    "        list(point_color[0, :3]) + [1.0]\n",
    "    ], N=30\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cmap = mymap\n",
    "norm = mpl.colors.Normalize(vmin=snr.min(), vmax=snr.max())\n",
    "\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax,\n",
    "                                cmap=cmap,\n",
    "                                norm=norm,\n",
    "                                orientation='horizontal')\n",
    "cb1.set_label('SNR')\n",
    "fig.show()\n",
    "plt.savefig(CHECKPOINT_FILENAME + 'colorbar.png', dpi=300)\n",
    "\n",
    "plt.style.use('default')\n",
    "# plt.style.use('science')\n",
    "\n",
    "# Idea: KDE plot but different stacked versions showing contours of the residual. Compare with other algorithms.\n",
    "\n",
    "palette = sns.color_palette(['#892665', '#B08431', '#294475', '#82A62E'])\n",
    "sns.set_palette(palette)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "sns.distplot((py-px)[(px<8.99)], hist=True, kde=True,\n",
    "             bins=30, ax=ax,\n",
    "             hist_kws={'edgecolor':'black', 'range': [-4, 4]},\n",
    "             kde_kws={'linewidth': 4, 'color': 'k'})\n",
    "ax.set_xlabel('Residual')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('RMS residual under 9: %.3f'% (np.sqrt(np.average(np.abs(py-px)[px<9])),))\n",
    "\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(0, 0.7)\n",
    "\n",
    "\n",
    "fig.savefig(CHECKPOINT_FILENAME + 'residual.pdf')\n",
    "\n",
    "labels = ['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a1', 'e1', 'i1', 'cos_Omega1', 'sin_Omega1', 'cos_pomega1', 'sin_pomega1', 'cos_theta1', 'sin_theta1', 'a2', 'e2', 'i2', 'cos_Omega2', 'sin_Omega2', 'cos_pomega2', 'sin_pomega2', 'cos_theta2', 'sin_theta2', 'a3', 'e3', 'i3', 'cos_Omega3', 'sin_Omega3', 'cos_pomega3', 'sin_pomega3', 'cos_theta3', 'sin_theta3', 'm1', 'm2', 'm3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n",
    "\n",
    "\n",
    "truths.shape#.reshape(-1)\n",
    "\n",
    "plt.style.use('default')\n",
    "# plt.style.use('science')\n",
    "fpr, tpr, _ = roc_curve(y_true=(truths>=9).reshape(-1),\n",
    "                        y_score=np.average(np.tile(sample_preds, (2, 1, 1))>9, 1).transpose(1, 0).reshape(-1))\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.plot(fpr, tpr, color=colors[0, 3])\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "y_roc = truths > 8.99\n",
    "\n",
    "y_score = np.average(sample_preds>= 9, axis=0)\n",
    "# ic(y_roc.shape, y_score.shape)\n",
    "\n",
    "y_roc = einops.rearrange(y_roc, 'sample run -> (sample run)')\n",
    "y_score = einops.repeat(y_score, 'sample -> (sample run)', run=2)\n",
    "\n",
    "# ic(y_roc.shape, y_score.shape)\n",
    "# # Use median of stds:\n",
    "# preds = np.median(_preds[..., 0], 0)\n",
    "# stds = np.median(_preds[..., 1], 0)\n",
    "snr = np.median(_preds[..., 0], 0)**2 / np.median(_preds[..., 1], 0)**2\n",
    "\n",
    "# Use std of samples:\n",
    "# snr =  np.average(sample_preds, axis=0)**2/np.std(sample_preds, axis=0)**2\n",
    "y_weight = einops.repeat(snr, 'sample -> (sample run)', run=2)\n",
    "\n",
    "\n",
    "roc = roc_auc_score(\n",
    "    y_true=y_roc,\n",
    "    y_score=y_score,\n",
    ")\n",
    "weight_roc = roc_auc_score(\n",
    "    y_true=y_roc,\n",
    "    y_score=y_score,\n",
    "    sample_weight=y_weight\n",
    ")\n",
    "plt.title('AUC ROC = %.3f'%(roc,))\n",
    "\n",
    "print(f'Model gets ROC of {roc:.3f}')\n",
    "print(f'Model gets weighted ROC of {weight_roc:.3f}')\n",
    "# summary_writer.add_figure(\n",
    "#     'roc_curve',\n",
    "#     fig)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "fig.savefig(CHECKPOINT_FILENAME + 'classification.pdf')\n",
    "\n",
    "if logger:\n",
    "    logger.log_metrics(metrics={'rmse': rmse,\n",
    "                                'snr_rmse': snr_rmse,\n",
    "                                'roc': roc,\n",
    "                                'weighted_roc': weight_roc,})\n",
    "    logger.log_metrics({\"classification\": wandb.Image(fig)})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn_chaos_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
