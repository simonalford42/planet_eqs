{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 24880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sca63/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  \"torch was imported before juliacall. This may cause a segfault. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Jupyter notebook. Loading juliacall extension. Set `PYSR_AUTOLOAD_EXTENSIONS=no` to disable.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import spock_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a1', 'e1', 'i1', 'cos_Omega1', 'sin_Omega1', 'cos_pomega1', 'sin_pomega1', 'cos_theta1', 'sin_theta1', 'a2', 'e2', 'i2', 'cos_Omega2', 'sin_Omega2', 'cos_pomega2', 'sin_pomega2', 'cos_theta2', 'sin_theta2', 'a3', 'e3', 'i3', 'cos_Omega3', 'sin_Omega3', 'cos_pomega3', 'sin_pomega3', 'cos_theta3', 'sin_theta3', 'm1', 'm2', 'm3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n",
    "\n",
    "# not all of these labels are actually used. for training, these inputs are zeroed out, but still passed in as zeroes.\n",
    "# ideally, the linear layer ignores them, which does happen if i do l1 regularization to it\n",
    "skipped = ['nan_mmr_near', 'nan_mmr_far', 'nan_megno', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno']\n",
    "\n",
    "assert len(labels) == 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a_1', 'e_1', 'i_1', '\\\\cos\\\\Omega_1', '\\\\sin\\\\Omega_1', '\\\\cos\\\\omega_1', '\\\\sin\\\\omega_1', '\\\\cos\\\\theta_1', '\\\\sin\\\\theta_1', 'a_2', 'e_2', 'i_2', '\\\\cos\\\\Omega_2', '\\\\sin\\\\Omega_2', '\\\\cos\\\\omega_2', '\\\\sin\\\\omega_2', '\\\\cos\\\\theta_2', '\\\\sin\\\\theta_2', 'a_3', 'e_3', 'i_3', '\\\\cos\\\\Omega_3', '\\\\sin\\\\Omega_3', '\\\\cos\\\\omega_3', '\\\\sin\\\\omega_3', '\\\\cos\\\\theta_3', '\\\\sin\\\\theta_3', 'm_1', 'm_2', 'm_3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n"
     ]
    }
   ],
   "source": [
    "def convert_to_latex(label):\n",
    "    # 1. if it ends in a number, add an underscore\n",
    "    if label[-1].isdigit():\n",
    "        label = label[:-1] + '_' + label[-1]\n",
    "    # 2. replace sin/cos with \\sin/\\cos\n",
    "    label = label.replace('sin', '\\\\sin')\n",
    "    label = label.replace('cos', '\\\\cos')\n",
    "    label = label.replace('_Omega', '\\\\Omega')\n",
    "    label = label.replace('_pomega', '\\\\omega')\n",
    "    label = label.replace('_theta', '\\\\theta')\n",
    "    return label\n",
    "\n",
    "latex_labels = [convert_to_latex(label) for label in labels]\n",
    "print(latex_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "ssX = StandardScaler()\n",
    "ssX.scale_ = np.array([2.88976974e+03, 6.10019661e-02, 4.03849732e-02, 4.81638693e+01,\n",
    "           6.72583662e-02, 4.17939679e-02, 8.15995339e+00, 2.26871589e+01,\n",
    "           4.73612029e-03, 7.09223721e-02, 3.06455099e-02, 7.10726478e-01,\n",
    "           7.03392022e-01, 7.07873597e-01, 7.06030923e-01, 7.04728204e-01,\n",
    "           7.09420909e-01, 1.90740659e-01, 4.75502285e-02, 2.77188320e-02,\n",
    "           7.08891412e-01, 7.05214134e-01, 7.09786887e-01, 7.04371833e-01,\n",
    "           7.04371110e-01, 7.09828420e-01, 3.33589977e-01, 5.20857790e-02,\n",
    "           2.84763136e-02, 7.02210626e-01, 7.11815232e-01, 7.10512240e-01,\n",
    "           7.03646004e-01, 7.08017286e-01, 7.06162814e-01, 2.12569430e-05,\n",
    "           2.35019125e-05, 2.04211110e-05, 7.51048890e-02, 3.94254400e-01,\n",
    "           7.11351099e-02])\n",
    "ssX.mean_ = np.array([ 4.95458585e+03,  5.67411891e-02,  3.83176945e-02,  2.97223474e+00,\n",
    "           6.29733979e-02,  3.50074471e-02,  6.72845676e-01,  9.92794768e+00,\n",
    "           9.99628430e-01,  5.39591547e-02,  2.92795061e-02,  2.12480714e-03,\n",
    "          -1.01500319e-02,  1.82667162e-02,  1.00813201e-02,  5.74404197e-03,\n",
    "           6.86570242e-03,  1.25316320e+00,  4.76946516e-02,  2.71326280e-02,\n",
    "           7.02054326e-03,  9.83378673e-03, -5.70616748e-03,  5.50782881e-03,\n",
    "          -8.44213953e-04,  2.05958338e-03,  1.57866569e+00,  4.31476211e-02,\n",
    "           2.73316392e-02,  1.05505555e-02,  1.03922250e-02,  7.36865006e-03,\n",
    "          -6.00523246e-04,  6.53016990e-03, -1.72038113e-03,  1.24807860e-05,\n",
    "           1.60314173e-05,  1.21732696e-05,  5.67292645e-03,  1.92488263e-01,\n",
    "           5.08607199e-03])\n",
    "ssX.var_ = ssX.scale_**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load when on the cluster\n",
    "model = spock_reg_model.load(version)\n",
    "feature_nn = model.feature_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load when local\n",
    "# feature_nn = torch.load(f'models/{version}_feature_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_linear = feature_nn.linear.weight * feature_nn.mask\n",
    "input_linear = input_linear.detach().numpy()\n",
    "if feature_nn.linear.bias is not None:\n",
    "    input_bias = feature_nn.linear.bias.detach().numpy()\n",
    "else:\n",
    "    input_bias = np.zeros(input_linear.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_i is the mean of the i'th feature, s_i is the standard deviation\n",
    "# get the linear transformation that creates feature i\n",
    "def linear_transformation(i):\n",
    "    return input_linear[i]\n",
    "\n",
    "# let's make the linear transformation a bit easier to read\n",
    "def format_num(x, latex=False):\n",
    "    if abs(x) > 1000:\n",
    "        x2 = 100 * (x // 100)\n",
    "        return str(x2)\n",
    "    # if abs(x) > 10:\n",
    "        # return f'{x:.0f}'\n",
    "    # if abs(x) > 1:\n",
    "        # return f'{x:.2f}'\n",
    "    # if abs(x) > 0.1:\n",
    "        # return f'{x:.2f}'\n",
    "    # if abs(x) > 0.01:\n",
    "        # return f'{x:.3f}'\n",
    "    # elif abs(x) > 0.001:\n",
    "        # return f'{x:.4f}'\n",
    "    else:\n",
    "        return f'{x:.3g}'\n",
    "\n",
    "format_vec = np.vectorize(format_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "sym_vars = {lbl: sp.Symbol(lbl, real=True) for lbl in labels}\n",
    "\n",
    "def simplify_scaled_feature(transformation, bias=0, include_ssx_bias=True):\n",
    "    # Create symbolic variables for each feature\n",
    "\n",
    "    expr = bias\n",
    "\n",
    "    # Add each transformed feature (unscaled)\n",
    "    for f_idx in range(len(labels)):\n",
    "        c = transformation[f_idx]\n",
    "        if c != 0:\n",
    "            label = labels[f_idx]\n",
    "            mean_j = ssX.mean_[f_idx] if include_ssx_bias else 0.0\n",
    "            scale_j = ssX.scale_[f_idx]\n",
    "            expr += c * (sym_vars[label] - mean_j) / scale_j\n",
    "\n",
    "    expr = sp.simplify(expr)\n",
    "    return expr\n",
    "\n",
    "def format_sympy_expr(expr, latex=False):\n",
    "    # replace labels with latex labels (change character from labels[i] to latex_labels[i])\n",
    "    if latex:\n",
    "        for lbl, sym in sym_vars.items():\n",
    "            i = labels.index(lbl)\n",
    "            new_lbl = latex_labels[i]\n",
    "            expr = expr.subs(sym, sp.Symbol(new_lbl, real=True))\n",
    "\n",
    "    coeffs = expr.as_coefficients_dict()\n",
    "\n",
    "    terms_str = []\n",
    "    const_str = None\n",
    "    for var, coef in coeffs.items():\n",
    "        if var == 1:\n",
    "            const_str = format_num(coef, latex)\n",
    "        else:\n",
    "            times = '' if latex else '*'\n",
    "            terms_str.append(f'{format_num(coef, latex)} {times} {var}')\n",
    "\n",
    "    if const_str is not None:\n",
    "        terms_str.append(const_str)\n",
    "\n",
    "    return ' + '.join(terms_str)\n",
    "\n",
    "def format_transformation(transformation, bias, latex):\n",
    "    sorted_ixs = np.argsort(np.abs(transformation))[::-1]\n",
    "    times = '' if latex else '*'\n",
    "    used_labels = latex_labels if latex else labels\n",
    "    features = [f'{format_num(transformation[i], latex)} {times} {used_labels[i]}' for i in sorted_ixs if transformation[i] != 0]\n",
    "    if bias != 0:\n",
    "        features = [format_num(bias, latex)] + features\n",
    "    return ' + '.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_feature_bias(i):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "    expr = simplify_scaled_feature(transformation, bias)\n",
    "    return expr.as_coefficients_dict().get(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pysr f2 equations\n",
    "import pickle\n",
    "reg = pickle.load(open('sr_results/11003.pkl', 'rb'))\n",
    "results = reg.equations_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = results.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = entry.sympy_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_to_mean_terms(expr):\n",
    "    replacements = {}\n",
    "    for symbol in expr.free_symbols:\n",
    "        if symbol.name.startswith('m') and symbol.name[1:].isdigit():\n",
    "            i = symbol.name[1:]  # get the number after 'm'\n",
    "            replacements[symbol] = symbol + get_scaled_feature_bias(int(i))\n",
    "    return expr.xreplace(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['sympy_format'] = results['sympy_format'].apply(add_bias_to_mean_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr.export_latex import sympy2latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_complexities(results, loss_gap = 0.25):\n",
    "    complexities = list(results['complexity'])\n",
    "    losses = list(results['loss'])\n",
    "    assert sorted(losses) == losses[::-1]\n",
    "\n",
    "    # important complexities are those that decrease the loss by more than loss_gap since the previous important complexity.\n",
    "    important_complexities = [complexities[0]]\n",
    "    current_loss = losses[0]\n",
    "\n",
    "    for i in range(1, len(complexities)):\n",
    "        if current_loss - losses[i] > loss_gap:\n",
    "            important_complexities.append(complexities[i])\n",
    "            current_loss = losses[i]\n",
    "\n",
    "    # automatically include the highest complexity too\n",
    "    if complexities[-1] != important_complexities[-1]:\n",
    "        important_complexities.append(complexities[-1])\n",
    "\n",
    "    return important_complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_complexities = get_important_complexities(results, loss_gap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_complexities = [3, 5, 14, 30]\n",
    "important_complexities = [1, 3, 4, 7, 11, 14, 22, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_indices = [i for i, c in enumerate(results['complexity']) if c in important_complexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 4, 6, 8, 15, 19]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sympy2latextable(reg.equations_[0], precision=2, columns=['equation', 'complexity', 'loss'], indices=important_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip([2, 4, 1, 6, 7, 8, 0, 3, 5, 9], range(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remap_latex_str(s):\n",
    "    # use regex so that we don't replace multiple times. from o3-mini-high\n",
    "    mapping_str = {str(old): str(new) for old, new in mapping_dict.items()}\n",
    "    pattern = re.compile(r'([ms])_\\{([^}]+)\\}')\n",
    "    def repl(match):\n",
    "        prefix, key = match.groups()\n",
    "        return f\"{prefix}_{{{mapping_str[key]}}}\" if key in mapping_str else match.group(0)\n",
    "    return pattern.sub(repl, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace m_{ with \\mu_{ and s_{ with \\sigma_{ and y = with \\log_{10} T_{\\text{inst}} =\n",
    "s = remap_latex_str(s)\n",
    "s = s.replace('m_{', '\\\\mu_{')\n",
    "s = s.replace('s_{', '\\\\sigma_{')\n",
    "s = s.replace('y =', '\\\\log_{10} T_{\\\\text{inst}} =')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\begin{center}\n",
      "\\begin{tabular}{@{}ccc@{}}\n",
      "\\toprule\n",
      "Equation & Complexity & Loss \\\\\n",
      "\\midrule\n",
      "$\\log_{10} T_{\\text{inst}} = 7.0$ & $1$ & $5.7$ \\\\\n",
      "$\\log_{10} T_{\\text{inst}} = 0.98 - \\mu_{0}$ & $3$ & $5.0$ \\\\\n",
      "$\\log_{10} T_{\\text{inst}} = 7.2 - \\sin{\\left(\\mu_{0} + 6.0 \\right)}$ & $4$ & $4.9$ \\\\\n",
      "$\\log_{10} T_{\\text{inst}} = - \\mu_{0} + \\frac{3.6}{\\sigma_{1}^{0.16}} - 6.0$ & $7$ & $3.3$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} \\log_{10} T_{\\text{inst}} = 0.14^{\\sigma_{2}} \\left(- \\mu_{0} + \\sigma_{1}^{-0.31} - 6.0\\right) + 3.7 \\end{dmath*} \\end{minipage} & $11$ & $2.7$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} \\log_{10} T_{\\text{inst}} = 0.059^{\\sigma_{2}} \\left(\\mu_{4} + \\sigma_{1}^{-0.33} - \\sin{\\left(\\mu_{0} + 6.0 \\right)} - 0.72\\right) + 3.7 \\end{dmath*} \\end{minipage} & $14$ & $2.5$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} \\log_{10} T_{\\text{inst}} = 0.067^{\\sigma_{2}} \\left(\\mu_{4} - \\sigma_{5} + \\left(\\sigma_{3}^{0.35} \\left(\\sigma_{0} + \\sigma_{1}\\right)\\right)^{-0.31} - \\sin{\\left(\\mu_{0} + 6.0 \\right)} - 0.72\\right) + 3.7 \\end{dmath*} \\end{minipage} & $22$ & $2.2$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} \\log_{10} T_{\\text{inst}} = 0.084^{\\sigma_{2}} \\cdot \\left(1.2^{2.1 \\cdot 10^{2} - \\mu_{2}} \\left(\\mu_{4} - \\sigma_{5} - 0.72\\right) + \\left(\\sigma_{3}^{0.36} \\left(\\sigma_{0} + \\sigma_{1}\\right)\\right)^{-0.31} - \\sin{\\left(\\mu_{0} + 6.0 \\right)}\\right) + 3.7 \\end{dmath*} \\end{minipage} & $26$ & $2.1$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can write it as a combination of the input features\n",
    "# we'll sort the features by their absolute value to make it a bit easier to read\n",
    "def feature_string(i, include_ssx=False, latex=False, include_ssx_bias=True):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "\n",
    "    if include_ssx:\n",
    "        expr = simplify_scaled_feature(transformation, bias, include_ssx_bias=include_ssx_bias)\n",
    "        s = format_sympy_expr(expr, latex)\n",
    "    else:\n",
    "        s = format_transformation(transformation, bias, latex)\n",
    "\n",
    "    # change + -'s to -'s\n",
    "    s = s.replace(' + -', ' - ')\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0481961363884*e1 - 34.9908344619683*e2 + 0.910846870277527\n",
      "209.781235963898*a1 + 85414.8542688018*m1 - 210.769332067401\n",
      "-4.01863051350855*a3 + 27051.5748154689*m1 + 6.00644919622817\n",
      "-1.10101459088907*sin_Omega2 + 0.763710665324014*sin_Omega3 + 0.00289048960447445\n",
      "-27.545810485898*a2 + 13.9602160286755*a3 + 12.4808819456433\n",
      "1.46652031263173*e1 + 29.1184195269148*e3 - 1.33552272919815\n",
      "37.5296375943142*i2 + 13.1045896905103*i3 - 1.37644761310641\n",
      "-4.91574016561418*e3 + 58430.5224859651*m2 - 0.724621594937567\n",
      "21.1436690517468*e1 - 4.47539705411287*e3 - 0.94779177292589\n",
      "0.957226289341714*e1 + 64678.2447691033*m3 - 0.83899683225858\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_linear.shape[0]):\n",
    "    print(simplify_scaled_feature(linear_transformation(i), include_ssx_bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_coeffs(i, include_ssx=False, latex=False, include_ssx_bias=True):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "\n",
    "    if include_ssx:\n",
    "        expr = simplify_scaled_feature(transformation, bias, include_ssx_bias=include_ssx_bias)\n",
    "        s = format_sympy_expr(expr, latex)\n",
    "    else:\n",
    "        s = format_transformation(transformation, bias, latex)\n",
    "\n",
    "    # change + -'s to -'s\n",
    "    s = s.replace(' + -', ' - ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_linear = feature_nn.linear.weight * feature_nn.mask\n",
    "input_linear = input_linear.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 14.0 * e1 - 35.0 * e2\n",
      "1: 210 * a1 + 85400 * m1\n",
      "2: 27000 * m1 - 4.02 * a3\n",
      "3: 0.764 * sin_Omega3 - 1.10 * sin_Omega2\n",
      "4: 14.0 * a3 - 27.5 * a2\n",
      "5: 29.1 * e3 + 1.47 * e1\n",
      "6: 13.1 * i3 + 37.5 * i2\n",
      "7: 58400 * m2 - 4.92 * e3\n",
      "8: 21.1 * e1 - 4.48 * e3\n",
      "9: 0.957 * e1 + 64600 * m3\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_linear.shape[0]):\n",
    "    print(str(i) + \": \" + feature_string(i, include_ssx=True, latex=False, include_ssx_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_string(include_ssx=False, include_ssx_bias=True):\n",
    "    s = ('\\\\begin{align*}\\n'\n",
    "        + f'ver&sion={version}\\\\\\\\'\n",
    "        + 'f_1& \\\\text{ features:} \\\\\\\\ \\n')\n",
    "\n",
    "    for i in range(input_linear.shape[0]):\n",
    "        s += f'    &{i}: {feature_string(i, include_ssx, latex=True, include_ssx_bias=include_ssx_bias)} \\\\\\\\ \\n'\n",
    "\n",
    "    s += '''\\end{align*}'''\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{align*}\n",
      "ver&sion=24880\\\\f_1& \\text{ features:} \\\\ \n",
      "    &0: 14.0  e_1 - 35.0  e_2 \\\\ \n",
      "    &1: 210  a_1 + 85400  m_1 \\\\ \n",
      "    &2: 27000  m_1 - 4.02  a_3 \\\\ \n",
      "    &3: 0.764  \\sin\\Omega_3 - 1.10  \\sin\\Omega_2 \\\\ \n",
      "    &4: 14.0  a_3 - 27.5  a_2 \\\\ \n",
      "    &5: 29.1  e_3 + 1.47  e_1 \\\\ \n",
      "    &6: 13.1  i_3 + 37.5  i_2 \\\\ \n",
      "    &7: 58400  m_2 - 4.92  e_3 \\\\ \n",
      "    &8: 21.1  e_1 - 4.48  e_3 \\\\ \n",
      "    &9: 0.957  e_1 + 64600  m_3 \\\\ \n",
      "\\end{align*}\n"
     ]
    }
   ],
   "source": [
    "print(latex_string(include_ssx=True, include_ssx_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$$\n",
       "\\begin{align*}\n",
       "ver&sion=24880\\\\f_1& \\text{ features:} \\\\ \n",
       "    &0: 14.0  e_1 - 35.0  e_2 + 0.911 \\\\ \n",
       "    &1: 210  a_1 + 85400  m_1 - 211 \\\\ \n",
       "    &2: 27000  m_1 - 4.02  a_3 + 6.01 \\\\ \n",
       "    &3: 0.764  \\sin\\Omega_3 - 1.10  \\sin\\Omega_2 + 0.00289 \\\\ \n",
       "    &4: 14.0  a_3 - 27.5  a_2 + 12.5 \\\\ \n",
       "    &5: 29.1  e_3 + 1.47  e_1 - 1.34 \\\\ \n",
       "    &6: 13.1  i_3 + 37.5  i_2 - 1.38 \\\\ \n",
       "    &7: 58400  m_2 - 4.92  e_3 - 0.725 \\\\ \n",
       "    &8: 21.1  e_1 - 4.48  e_3 - 0.948 \\\\ \n",
       "    &9: 0.957  e_1 + 64600  m_3 - 0.839 \\\\ \n",
       "\\end{align*}\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown('$$\\n' + latex_string(include_ssx=True) + '\\n$$'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
