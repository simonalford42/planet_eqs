{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 10290  # eps = 0.001\n",
    "# version = 9259  # eps = 0.1\n",
    "version = 74649  # k = 3\n",
    "# version = 11566  # k = 4\n",
    "# version = 21622 # M\n",
    "# version = 72646 # k = 5\n",
    "# version = 93703 # M, k=3\n",
    "# version = 56780 # M, k=4\n",
    "version = 24880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sca63/.conda/envs/bnn_chaos_model/lib/python3.7/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  \"torch was imported before juliacall. This may cause a segfault. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Jupyter notebook. Loading juliacall extension. Set `PYSR_AUTOLOAD_EXTENSIONS=no` to disable.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import spock_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a1', 'e1', 'i1', 'cos_Omega1', 'sin_Omega1', 'cos_pomega1', 'sin_pomega1', 'cos_theta1', 'sin_theta1', 'a2', 'e2', 'i2', 'cos_Omega2', 'sin_Omega2', 'cos_pomega2', 'sin_pomega2', 'cos_theta2', 'sin_theta2', 'a3', 'e3', 'i3', 'cos_Omega3', 'sin_Omega3', 'cos_pomega3', 'sin_pomega3', 'cos_theta3', 'sin_theta3', 'm1', 'm2', 'm3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n",
    "\n",
    "# not all of these labels are actually used. for training, these inputs are zeroed out, but still passed in as zeroes.\n",
    "# ideally, the linear layer ignores them, which does happen if i do l1 regularization to it\n",
    "skipped = ['nan_mmr_near', 'nan_mmr_far', 'nan_megno', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 a2\n",
      "26 a3\n",
      "3 max_strength_mmr_near\n",
      "27 e3\n",
      "9 e1\n",
      "4 e+_far\n",
      "8 a1\n",
      "4 e+_far\n",
      "19 i2\n",
      "35 m1\n"
     ]
    }
   ],
   "source": [
    "for i in [17, 26, 3, 27, 9, 4, 8, 4, 19, 35]:\n",
    "    print(f'{i}', labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a_1', 'e_1', 'i_1', '\\\\cos\\\\Omega_1', '\\\\sin\\\\Omega_1', '\\\\cos\\\\omega_1', '\\\\sin\\\\omega_1', '\\\\cos\\\\theta_1', '\\\\sin\\\\theta_1', 'a_2', 'e_2', 'i_2', '\\\\cos\\\\Omega_2', '\\\\sin\\\\Omega_2', '\\\\cos\\\\omega_2', '\\\\sin\\\\omega_2', '\\\\cos\\\\theta_2', '\\\\sin\\\\theta_2', 'a_3', 'e_3', 'i_3', '\\\\cos\\\\Omega_3', '\\\\sin\\\\Omega_3', '\\\\cos\\\\omega_3', '\\\\sin\\\\omega_3', '\\\\cos\\\\theta_3', '\\\\sin\\\\theta_3', 'm_1', 'm_2', 'm_3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n"
     ]
    }
   ],
   "source": [
    "def convert_to_latex(label):\n",
    "    # 1. if it ends in a number, add an underscore\n",
    "    if label[-1].isdigit():\n",
    "        label = label[:-1] + '_' + label[-1]\n",
    "    # 2. replace sin/cos with \\sin/\\cos\n",
    "    label = label.replace('sin', '\\\\sin')\n",
    "    label = label.replace('cos', '\\\\cos')\n",
    "    label = label.replace('_Omega', '\\\\Omega')\n",
    "    label = label.replace('_pomega', '\\\\omega')\n",
    "    label = label.replace('_theta', '\\\\theta')\n",
    "    return label\n",
    "\n",
    "latex_labels = [convert_to_latex(label) for label in labels]\n",
    "print(latex_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "ssX = StandardScaler()\n",
    "ssX.scale_ = np.array([2.88976974e+03, 6.10019661e-02, 4.03849732e-02, 4.81638693e+01,\n",
    "           6.72583662e-02, 4.17939679e-02, 8.15995339e+00, 2.26871589e+01,\n",
    "           4.73612029e-03, 7.09223721e-02, 3.06455099e-02, 7.10726478e-01,\n",
    "           7.03392022e-01, 7.07873597e-01, 7.06030923e-01, 7.04728204e-01,\n",
    "           7.09420909e-01, 1.90740659e-01, 4.75502285e-02, 2.77188320e-02,\n",
    "           7.08891412e-01, 7.05214134e-01, 7.09786887e-01, 7.04371833e-01,\n",
    "           7.04371110e-01, 7.09828420e-01, 3.33589977e-01, 5.20857790e-02,\n",
    "           2.84763136e-02, 7.02210626e-01, 7.11815232e-01, 7.10512240e-01,\n",
    "           7.03646004e-01, 7.08017286e-01, 7.06162814e-01, 2.12569430e-05,\n",
    "           2.35019125e-05, 2.04211110e-05, 7.51048890e-02, 3.94254400e-01,\n",
    "           7.11351099e-02])\n",
    "ssX.mean_ = np.array([ 4.95458585e+03,  5.67411891e-02,  3.83176945e-02,  2.97223474e+00,\n",
    "           6.29733979e-02,  3.50074471e-02,  6.72845676e-01,  9.92794768e+00,\n",
    "           9.99628430e-01,  5.39591547e-02,  2.92795061e-02,  2.12480714e-03,\n",
    "          -1.01500319e-02,  1.82667162e-02,  1.00813201e-02,  5.74404197e-03,\n",
    "           6.86570242e-03,  1.25316320e+00,  4.76946516e-02,  2.71326280e-02,\n",
    "           7.02054326e-03,  9.83378673e-03, -5.70616748e-03,  5.50782881e-03,\n",
    "          -8.44213953e-04,  2.05958338e-03,  1.57866569e+00,  4.31476211e-02,\n",
    "           2.73316392e-02,  1.05505555e-02,  1.03922250e-02,  7.36865006e-03,\n",
    "          -6.00523246e-04,  6.53016990e-03, -1.72038113e-03,  1.24807860e-05,\n",
    "           1.60314173e-05,  1.21732696e-05,  5.67292645e-03,  1.92488263e-01,\n",
    "           5.08607199e-03])\n",
    "ssX.var_ = ssX.scale_**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load when on the cluster\n",
    "model = spock_reg_model.load(version)\n",
    "feature_nn = model.feature_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load when local\n",
    "# feature_nn = torch.load(f'models/{version}_feature_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_linear = feature_nn.linear.weight * feature_nn.mask\n",
    "input_linear = input_linear.detach().numpy()\n",
    "if feature_nn.linear.bias is not None:\n",
    "    input_bias = feature_nn.linear.bias.detach().numpy()\n",
    "else:\n",
    "    input_bias = np.zeros(input_linear.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_i is the mean of the i'th feature, s_i is the standard deviation\n",
    "# get the linear transformation that creates feature i\n",
    "def linear_transformation(i):\n",
    "    return input_linear[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the linear transformation a bit easier to read\n",
    "def format_num(x, latex=False):\n",
    "    if abs(x) > 1000:\n",
    "        x2 = 100 * (x // 100)\n",
    "        return str(x2)\n",
    "    # if abs(x) > 10:\n",
    "        # return f'{x:.0f}'\n",
    "    # if abs(x) > 1:\n",
    "        # return f'{x:.2f}'\n",
    "    # if abs(x) > 0.1:\n",
    "        # return f'{x:.2f}'\n",
    "    # if abs(x) > 0.01:\n",
    "        # return f'{x:.3f}'\n",
    "    # elif abs(x) > 0.001:\n",
    "        # return f'{x:.4f}'\n",
    "    else:\n",
    "        return f'{x:.3g}'\n",
    "\n",
    "format_vec = np.vectorize(format_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "sym_vars = {lbl: sp.Symbol(lbl, real=True) for lbl in labels}\n",
    "\n",
    "def simplify_scaled_feature(transformation, bias=0, include_ssx_bias=True):\n",
    "    # Create symbolic variables for each feature\n",
    "\n",
    "    expr = bias\n",
    "\n",
    "    # Add each transformed feature (unscaled)\n",
    "    for f_idx in range(len(labels)):\n",
    "        c = transformation[f_idx]\n",
    "        if c != 0:\n",
    "            label = labels[f_idx]\n",
    "            mean_j = ssX.mean_[f_idx] if include_ssx_bias else 0.0\n",
    "            scale_j = ssX.scale_[f_idx]\n",
    "            expr += c * (sym_vars[label] - mean_j) / scale_j\n",
    "\n",
    "    expr = sp.simplify(expr)\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sympy_expr(expr, latex=False):\n",
    "    # replace labels with latex labels (change character from labels[i] to latex_labels[i])\n",
    "    if latex:\n",
    "        for lbl, sym in sym_vars.items():\n",
    "            i = labels.index(lbl)\n",
    "            new_lbl = latex_labels[i]\n",
    "            expr = expr.subs(sym, sp.Symbol(new_lbl, real=True))\n",
    "\n",
    "    coeffs = expr.as_coefficients_dict()\n",
    "\n",
    "    terms_str = []\n",
    "    const_str = None\n",
    "    for var, coef in coeffs.items():\n",
    "        if var == 1:\n",
    "            const_str = format_num(coef, latex)\n",
    "        else:\n",
    "            times = '' if latex else '*'\n",
    "            terms_str.append(f'{format_num(coef, latex)} {times} {var}')\n",
    "\n",
    "    if const_str is not None:\n",
    "        terms_str.append(const_str)\n",
    "\n",
    "    return ' + '.join(terms_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_transformation(transformation, bias, latex):\n",
    "    sorted_ixs = np.argsort(np.abs(transformation))[::-1]\n",
    "    times = '' if latex else '*'\n",
    "    used_labels = latex_labels if latex else labels\n",
    "    features = [f'{format_num(transformation[i], latex)} {times} {used_labels[i]}' for i in sorted_ixs if transformation[i] != 0]\n",
    "    if bias != 0:\n",
    "        features = [format_num(bias, latex)] + features\n",
    "    return ' + '.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = simplify_scaled_feature(linear_transformation(0), bias=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_feature_bias(i):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "    expr = simplify_scaled_feature(transformation, bias)\n",
    "    return expr.as_coefficients_dict().get(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pysr f2 equations\n",
    "import pickle\n",
    "reg = pickle.load(open('sr_results/11003.pkl', 'rb'))\n",
    "results = reg.equations_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = results.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = entry.sympy_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_to_mean_terms(expr):\n",
    "    replacements = {}\n",
    "    for symbol in expr.free_symbols:\n",
    "        if symbol.name.startswith('m') and symbol.name[1:].isdigit():\n",
    "            i = symbol.name[1:]  # get the number after 'm'\n",
    "            replacements[symbol] = symbol + get_scaled_feature_bias(int(i))\n",
    "    return expr.xreplace(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['sympy_format'] = results['sympy_format'].apply(add_bias_to_mean_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr.export_latex import sympy2latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_complexities(results, loss_gap = 0.25):\n",
    "    complexities = list(results['complexity'])\n",
    "    losses = list(results['loss'])\n",
    "    assert sorted(losses) == losses[::-1]\n",
    "\n",
    "    # important complexities are those that decrease the loss by more than loss_gap since the previous important complexity.\n",
    "    important_complexities = [complexities[0]]\n",
    "    current_loss = losses[0]\n",
    "\n",
    "    for i in range(1, len(complexities)):\n",
    "        if current_loss - losses[i] > loss_gap:\n",
    "            important_complexities.append(complexities[i])\n",
    "            current_loss = losses[i]\n",
    "\n",
    "    # automatically include the highest complexity too\n",
    "    if complexities[-1] != important_complexities[-1]:\n",
    "        important_complexities.append(complexities[-1])\n",
    "\n",
    "    return important_complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_complexities = get_important_complexities(results, loss_gap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_indices = [i for i, c in enumerate(results['complexity']) if c in important_complexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\begin{center}\n",
      "\\begin{tabular}{@{}ccc@{}}\n",
      "\\toprule\n",
      "Equation & Complexity & Loss \\\\\n",
      "\\midrule\n",
      "$y = 7.0$ & $1$ & $5.7$ \\\\\n",
      "$y = 0.98 - m_{2}$ & $3$ & $5.0$ \\\\\n",
      "$y = \\frac{3.6}{s_{4}^{0.15}}$ & $5$ & $4.0$ \\\\\n",
      "$y = - m_{2} + \\frac{3.6}{s_{4}^{0.16}} - 6.0$ & $7$ & $3.3$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} y = 0.14^{s_{1}} \\left(- m_{2} + s_{4}^{-0.31} - 6.0\\right) + 3.7 \\end{dmath*} \\end{minipage} & $11$ & $2.7$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} y = 0.084^{s_{1}} \\left(- 0.67 m_{2} + 0.67 m_{7} + s_{4}^{-0.33} - 0.67 s_{6} - 4.5\\right) + 3.7 \\end{dmath*} \\end{minipage} & $17$ & $2.4$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} y = \\left(0.059^{s_{1}} - s_{2}\\right) \\left(m_{7} - s_{8} + \\left(\\left(s_{2} + s_{4}\\right) \\sin{\\left(s_{6}^{0.35} \\right)}\\right)^{-0.31} - \\sin{\\left(m_{2} + 6.0 \\right)} - 0.72\\right) + 3.7 \\end{dmath*} \\end{minipage} & $25$ & $2.2$ \\\\\n",
      "\\begin{minipage}{0.8\\linewidth} \\vspace{-1em} \\begin{dmath*} y = 3.4 + \\frac{- m_{2} + 0.40 m_{7} - 0.40 m_{8} + \\left(s_{4} s_{6}^{0.17}\\right)^{-0.31} - 5.9}{2.2 s_{1} + 2.2 s_{4} + \\left(0.91^{m_{4} + 12.}\\right)^{-0.21}} \\end{dmath*} \\end{minipage} & $30$ & $2.0$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(sympy2latextable(reg.equations_[0], precision=2, columns=['equation', 'complexity', 'loss'], indices=important_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can write it as a combination of the input features\n",
    "# we'll sort the features by their absolute value to make it a bit easier to read\n",
    "def feature_string(i, include_ssx=False, latex=False, include_ssx_bias=True):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "\n",
    "    if include_ssx:\n",
    "        expr = simplify_scaled_feature(transformation, bias, include_ssx_bias=include_ssx_bias)\n",
    "        s = format_sympy_expr(expr, latex)\n",
    "    else:\n",
    "        s = format_transformation(transformation, bias, latex)\n",
    "\n",
    "    # change + -'s to -'s\n",
    "    s = s.replace(' + -', ' - ')\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 14.0 * e1 - 35.0 * e2\n",
      "1: 210 * a1 + 85400 * m1\n",
      "2: 27000 * m1 - 4.02 * a3\n",
      "3: 0.764 * sin_Omega3 - 1.10 * sin_Omega2\n",
      "4: 14.0 * a3 - 27.5 * a2\n",
      "5: 29.1 * e3 + 1.47 * e1\n",
      "6: 13.1 * i3 + 37.5 * i2\n",
      "7: 58400 * m2 - 4.92 * e3\n",
      "8: 21.1 * e1 - 4.48 * e3\n",
      "9: 0.957 * e1 + 64600 * m3\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_linear.shape[0]):\n",
    "    print(str(i) + \": \" + feature_string(i, include_ssx=True, latex=False, include_ssx_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_string(include_ssx=False, include_ssx_bias=True):\n",
    "    s = ('\\\\begin{align*}\\n'\n",
    "        + f'ver&sion={version}\\\\\\\\'\n",
    "        + 'f_1& \\\\text{ features:} \\\\\\\\ \\n')\n",
    "\n",
    "    for i in range(input_linear.shape[0]):\n",
    "        s += f'    &{i}: {feature_string(i, include_ssx, latex=True, include_ssx_bias=include_ssx_bias)} \\\\\\\\ \\n'\n",
    "\n",
    "    s += '''\\end{align*}'''\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{align*}\n",
      "ver&sion=24880\\\\f_1& \\text{ features:} \\\\ \n",
      "    &0: 14.0  e_1 - 35.0  e_2 \\\\ \n",
      "    &1: 210  a_1 + 85400  m_1 \\\\ \n",
      "    &2: 27000  m_1 - 4.02  a_3 \\\\ \n",
      "    &3: 0.764  \\sin\\Omega_3 - 1.10  \\sin\\Omega_2 \\\\ \n",
      "    &4: 14.0  a_3 - 27.5  a_2 \\\\ \n",
      "    &5: 29.1  e_3 + 1.47  e_1 \\\\ \n",
      "    &6: 13.1  i_3 + 37.5  i_2 \\\\ \n",
      "    &7: 58400  m_2 - 4.92  e_3 \\\\ \n",
      "    &8: 21.1  e_1 - 4.48  e_3 \\\\ \n",
      "    &9: 0.957  e_1 + 64600  m_3 \\\\ \n",
      "\\end{align*}\n"
     ]
    }
   ],
   "source": [
    "print(latex_string(include_ssx=True, include_ssx_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$$\n",
       "\\begin{align*}\n",
       "ver&sion=24880\\\\f_1& \\text{ features:} \\\\ \n",
       "    &0: 14.0  e_1 - 35.0  e_2 + 0.911 \\\\ \n",
       "    &1: 210  a_1 + 85400  m_1 - 211 \\\\ \n",
       "    &2: 27000  m_1 - 4.02  a_3 + 6.01 \\\\ \n",
       "    &3: 0.764  \\sin\\Omega_3 - 1.10  \\sin\\Omega_2 + 0.00289 \\\\ \n",
       "    &4: 14.0  a_3 - 27.5  a_2 + 12.5 \\\\ \n",
       "    &5: 29.1  e_3 + 1.47  e_1 - 1.34 \\\\ \n",
       "    &6: 13.1  i_3 + 37.5  i_2 - 1.38 \\\\ \n",
       "    &7: 58400  m_2 - 4.92  e_3 - 0.725 \\\\ \n",
       "    &8: 21.1  e_1 - 4.48  e_3 - 0.948 \\\\ \n",
       "    &9: 0.957  e_1 + 64600  m_3 - 0.839 \\\\ \n",
       "\\end{align*}\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown('$$\\n' + latex_string(include_ssx=True) + '\\n$$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 24880\n",
    "model = spock_reg_model.load(version)\n",
    "feature_nn = model.feature_nn\n",
    "\n",
    "input_linear = feature_nn.linear.weight * feature_nn.mask\n",
    "input_linear = input_linear.detach().numpy()\n",
    "if feature_nn.linear.bias is not None:\n",
    "    input_bias = feature_nn.linear.bias.detach().numpy()\n",
    "else:\n",
    "    input_bias = np.zeros(input_linear.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero(arr):\n",
    "    return arr[arr.nonzero()], arr.nonzero()\n",
    "\n",
    "def set_nonzero(arr, values, indices):\n",
    "    arr[indices] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(x, y, epsilon=0.1, zeroing_allowed=True):\n",
    "    if x == 0 and y == 0:\n",
    "        return (0, 0, 1), 0\n",
    "    if x == 0:\n",
    "        return (0, 1, 1/y), 0\n",
    "    if y == 0:\n",
    "        return (1, 0, 1/x), 0\n",
    "\n",
    "    best_simplification, best_magnitude, best_error = None, None, None\n",
    "    possible_values = list(range(-10, 11))\n",
    "    candidate_ratios = [(a, c) for a in possible_values for c in possible_values]\n",
    "\n",
    "    for a, b in candidate_ratios:\n",
    "        if not zeroing_allowed and (a == 0 or b == 0):\n",
    "            continue\n",
    "\n",
    "        k = 1\n",
    "        if a != 0:\n",
    "            k = x / a\n",
    "        if b != 0 and (a == 0 or abs(y) > abs(x)):\n",
    "            k = y / b\n",
    "\n",
    "        if k < 0: continue\n",
    "        x2, y2 = k * a, k * b\n",
    "\n",
    "        error = abs(x - x2) + abs(y - y2)\n",
    "        # should be measured with the normalized values, not the original.\n",
    "        if error >= epsilon: continue\n",
    "\n",
    "        magnitude = abs(a) + abs(b)\n",
    "\n",
    "        if best_error is None or magnitude < best_magnitude or magnitude == best_magnitude and error < best_error:\n",
    "            best_simplification, best_error, best_magnitude = (a, b, x2, y2), error, magnitude\n",
    "\n",
    "    return best_simplification, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_stuff(input_linear, epsilon=0.1, normalize=True, zeroing_allowed=True):\n",
    "    input_linear2 = input_linear.copy()\n",
    "    for i in range(input_linear.shape[0]):\n",
    "        nonzero, indices = get_nonzero(input_linear[i])\n",
    "        x, y = nonzero\n",
    "        print('original:\\t', f'{x:.3f} {y:.3f}')\n",
    "\n",
    "        if normalize:\n",
    "            l1 = abs(x) + abs(y)\n",
    "            x, y = x / l1, y / l1\n",
    "            print('normalized:\\t', f'{x:.3f} {y:.3f}')\n",
    "\n",
    "        simplification, error = simplify(x, y, epsilon=epsilon, zeroing_allowed=zeroing_allowed)\n",
    "        if simplification is None:\n",
    "            print(\"no simplification found\")\n",
    "            nonzero = [x, y]\n",
    "        else:\n",
    "            a, b, x2, y2 = simplification\n",
    "            print(\"new values:\\t\", f\"{x2:.3f} {y2:.3f}\", \"with error\", f\"{error:.3f}\")\n",
    "            print(\"ratio:\\t\\t\", f\"{a} {b}\")\n",
    "            nonzero = [x2, y2]\n",
    "\n",
    "            if normalize:\n",
    "                l1 = abs(x2) + abs(y2)\n",
    "                x2, y2 = x2 / l1, y2 / l1\n",
    "                print(\"final normed:\\t\", f\"{x2:.3f} {y2:.3f}\")\n",
    "                nonzero = [x2, y2]\n",
    "\n",
    "\n",
    "        print()\n",
    "        set_nonzero(input_linear2[i], nonzero, indices)\n",
    "\n",
    "    input_linear2 = torch.tensor(input_linear2)\n",
    "    feature_nn.linear.weight = torch.nn.Parameter(input_linear2)\n",
    "\n",
    "    s = '24880_feature_nn_simplified_v3_'\n",
    "    # if normalize:\n",
    "        # s += 'norm_'\n",
    "    # if not zeroing_allowed:\n",
    "        # s += 'nozero_'\n",
    "    s += f'eps={epsilon}.pt'\n",
    "\n",
    "    torch.save(feature_nn, s)\n",
    "    print(f'saved to', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify_stuff(input_linear, epsilon=0.001, normalize=True, zeroing_allowed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "ssX = StandardScaler()\n",
    "ssX.scale_ = np.array([2.88976974e+03, 6.10019661e-02, 4.03849732e-02, 4.81638693e+01,\n",
    "           6.72583662e-02, 4.17939679e-02, 8.15995339e+00, 2.26871589e+01,\n",
    "           4.73612029e-03, 7.09223721e-02, 3.06455099e-02, 7.10726478e-01,\n",
    "           7.03392022e-01, 7.07873597e-01, 7.06030923e-01, 7.04728204e-01,\n",
    "           7.09420909e-01, 1.90740659e-01, 4.75502285e-02, 2.77188320e-02,\n",
    "           7.08891412e-01, 7.05214134e-01, 7.09786887e-01, 7.04371833e-01,\n",
    "           7.04371110e-01, 7.09828420e-01, 3.33589977e-01, 5.20857790e-02,\n",
    "           2.84763136e-02, 7.02210626e-01, 7.11815232e-01, 7.10512240e-01,\n",
    "           7.03646004e-01, 7.08017286e-01, 7.06162814e-01, 2.12569430e-05,\n",
    "           2.35019125e-05, 2.04211110e-05, 7.51048890e-02, 3.94254400e-01,\n",
    "           7.11351099e-02])\n",
    "ssX.mean_ = np.array([ 4.95458585e+03,  5.67411891e-02,  3.83176945e-02,  2.97223474e+00,\n",
    "           6.29733979e-02,  3.50074471e-02,  6.72845676e-01,  9.92794768e+00,\n",
    "           9.99628430e-01,  5.39591547e-02,  2.92795061e-02,  2.12480714e-03,\n",
    "          -1.01500319e-02,  1.82667162e-02,  1.00813201e-02,  5.74404197e-03,\n",
    "           6.86570242e-03,  1.25316320e+00,  4.76946516e-02,  2.71326280e-02,\n",
    "           7.02054326e-03,  9.83378673e-03, -5.70616748e-03,  5.50782881e-03,\n",
    "          -8.44213953e-04,  2.05958338e-03,  1.57866569e+00,  4.31476211e-02,\n",
    "           2.73316392e-02,  1.05505555e-02,  1.03922250e-02,  7.36865006e-03,\n",
    "          -6.00523246e-04,  6.53016990e-03, -1.72038113e-03,  1.24807860e-05,\n",
    "           1.60314173e-05,  1.21732696e-05,  5.67292645e-03,  1.92488263e-01,\n",
    "           5.08607199e-03])\n",
    "ssX.var_ = ssX.scale_**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn_chaos_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
