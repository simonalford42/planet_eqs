{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pysr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['time', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno', 'a1', 'e1', 'i1', 'cos_Omega1', 'sin_Omega1', 'cos_pomega1', 'sin_pomega1', 'cos_theta1', 'sin_theta1', 'a2', 'e2', 'i2', 'cos_Omega2', 'sin_Omega2', 'cos_pomega2', 'sin_pomega2', 'cos_theta2', 'sin_theta2', 'a3', 'e3', 'i3', 'cos_Omega3', 'sin_Omega3', 'cos_pomega3', 'sin_pomega3', 'cos_theta3', 'sin_theta3', 'm1', 'm2', 'm3', 'nan_mmr_near', 'nan_mmr_far', 'nan_megno']\n",
    "\n",
    "# not all of these labels are actually used. for training, these inputs are zeroed out, but still passed in as zeroes.\n",
    "# ideally, the linear layer ignores them, which does happen if i do l1 regularization to it\n",
    "skipped = ['nan_mmr_near', 'nan_mmr_far', 'nan_megno', 'e+_near', 'e-_near', 'max_strength_mmr_near', 'e+_far', 'e-_far', 'max_strength_mmr_far', 'megno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# l1 reg = 2: 95944\n",
    "# feature_nn = torch.load('models/95944_feature_nn.pt')\n",
    "\n",
    "# l1 reg = 0.2: 92122\n",
    "# feature_nn = torch.load('models/92122_feature_nn.pt')\n",
    "\n",
    "# l1 nonabs reg: 63524\n",
    "# feature_nn = torch.load('models/63524_feature_nn.pt')\n",
    "\n",
    "# topk 2 pruned masked linear\n",
    "feature_nn = torch.load('models/52410_feature_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedLinear' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this gives the (n_features, n_inputs) matrix of the linear transformation used as f1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_linear \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m input_linear\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskedLinear' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "# this gives the (n_features, n_inputs) matrix of the linear transformation used as f1\n",
    "input_linear = feature_nn.weight.detach().numpy()\n",
    "input_bias = feature_nn.bias.detach().numpy()\n",
    "input_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_linear = feature_nn.mask * feature_nn.linear.weight\n",
    "input_linear = input_linear.detach().numpy()\n",
    "input_bias = feature_nn.linear.bias.detach().numpy()\n",
    "torch.save(input_linear, 'models/52410_input_linear.pt')\n",
    "torch.save(input_bias, 'models/52410_input_bias.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# m_i is the mean of the i'th feature, s_i is the standard deviation\n",
    "# get the linear transformation that creates feature i\n",
    "def linear_transformation(i):\n",
    "    return input_linear[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's make the linear transformation a bit easier to read\n",
    "def format_num(x):\n",
    "    if abs(x) > 0.1:\n",
    "        return f'{x:.2f}'\n",
    "    if abs(x) > 0.01:\n",
    "        return f'{x:.3f}'\n",
    "    elif abs(x) > 0.001:\n",
    "        return f'{x:.4f}'\n",
    "    else:\n",
    "        return f'{x:.2e}'\n",
    "\n",
    "format_vec = np.vectorize(format_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now we can write it as a combination of the input features\n",
    "# we'll sort the features by their absolute value to make it a bit easier to read\n",
    "def feature_equation(i):\n",
    "    transformation = linear_transformation(i)\n",
    "    bias = input_bias[i]\n",
    "    sorted_ixs = np.argsort(np.abs(transformation))[::-1]\n",
    "    return [format_num(bias)] + [format_num(transformation[i]) + ' * ' + labels[i] for i in sorted_ixs if transformation[i] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0:\n",
      "-0.0055 + -1.53 * m1 + 0.35 * a3\n",
      "\n",
      "feature 1:\n",
      "0.0080 + 0.78 * e3 + -0.22 * e2\n",
      "\n",
      "feature 2:\n",
      "0.0083 + 0.85 * e2 + -0.0058 * i1\n",
      "\n",
      "feature 3:\n",
      "0.0015 + -0.28 * sin_Omega2 + 0.11 * sin_Omega1\n",
      "\n",
      "feature 4:\n",
      "-0.0014 + 1.81 * a1 + -0.011 * e1\n",
      "\n",
      "feature 5:\n",
      "0.0084 + -3.93 * a2 + 3.71 * a3\n",
      "\n",
      "feature 6:\n",
      "-3.17e-05 + -1.11e-04 * i2 + 1.71e-05 * e2\n",
      "\n",
      "feature 7:\n",
      "-2.67e-04 + -5.35e-05 * m1 + 1.34e-05 * a2\n",
      "\n",
      "feature 8:\n",
      "-0.0017 + -0.42 * i3 + -0.0025 * i1\n",
      "\n",
      "feature 9:\n",
      "-0.011 + -1.11 * m2 + 0.011 * i1\n",
      "\n",
      "feature 10:\n",
      "-5.91e-04 + -0.29 * sin_Omega3 + 0.053 * sin_Omega2\n",
      "\n",
      "feature 11:\n",
      "-0.0014 + 0.21 * cos_Omega2 + -0.16 * cos_Omega3\n",
      "\n",
      "feature 12:\n",
      "2.27e-05 + 2.78e-05 * cos_Omega2 + -1.71e-05 * a2\n",
      "\n",
      "feature 13:\n",
      "0.013 + 1.32 * m3 + -0.26 * a3\n",
      "\n",
      "feature 14:\n",
      "8.41e-05 + 6.71e-05 * sin_Omega2 + -1.99e-06 * a2\n",
      "\n",
      "feature 15:\n",
      "-2.57e-05 + 0.0010 * sin_pomega3 + 4.77e-05 * sin_Omega1\n",
      "\n",
      "feature 16:\n",
      "-4.55e-04 + 0.86 * e1 + -0.35 * e2\n",
      "\n",
      "feature 17:\n",
      "0.0070 + 0.86 * a3 + 0.36 * a2\n",
      "\n",
      "feature 18:\n",
      "0.0015 + 0.44 * i2 + 0.054 * i1\n",
      "\n",
      "feature 19:\n",
      "-0.0016 + -0.44 * i1 + -0.017 * cos_Omega1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(input_linear.shape[0]):\n",
    "    print(f'feature {i}:')\n",
    "    # print(' +\\n'.join(feature_equation(i)[:10]))\n",
    "    print(' + '.join(feature_equation(i)))\n",
    "    # print('+ ... (smaller terms omitted)')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
